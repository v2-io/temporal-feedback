# TF-03: The Model (Formulation)

Any persisting agent maintains a **model** — a compressed representation of its interaction history that supports prediction and action selection.

## Definitions

**Interaction History** ($\mathcal{H}_t$): The complete record of observations and actions available to the agent:

*[Definition]*
$$\mathcal{H}_t = (o_1, a_1, o_2, a_2, \ldots, a_{t-1}, o_t)$$

This is the agent's *only* raw material. Everything the agent "knows" must be constructed from this.

**Model** ($M_t$): A compression of the interaction history:

*[Definition]*
$$M_t = \phi(\mathcal{H}_t)$$

where $\phi: \mathcal{H}^* \to \mathcal{M}$ maps histories to elements of a **model space** $\mathcal{M}$.

**Model Space** ($\mathcal{M}$): The set of representable models. This is a structural choice that constrains what the agent can represent:

| Model Space $\mathcal{M}$ | Instance |
|----------------------------|----------|
| $\mathbb{R}^n \times \mathbb{S}^n_{++}$ (vector + covariance) | Kalman filter |
| $\Delta(\Theta)$ (distributions over parameters) | Bayesian agent |
| $\{Q: \mathcal{S} \times \mathcal{A} \to \mathbb{R}\}$ (value functions) | RL agent |
| Neural network weight space | Deep learning agent |
| $\mathbb{R}^3$ (error, integral, derivative) | PID controller |
| (Procedures, beliefs, culture) | Organization |
| Antibody repertoire + memory cells | Immune system |

## The Sufficient Statistic Property

A model is **adequate** to the degree that it is a sufficient statistic for the history with respect to future prediction. Formally, define **model sufficiency**:

*[Definition]*
$$S(M_t) = 1 - \frac{I(\mathcal{H}_t \,;\, o_{t+1:\infty} \mid M_t, a_{t:\infty})}{I(\mathcal{H}_t \,;\, o_{t+1:\infty} \mid a_{t:\infty})}$$

When $S = 1$: the model captures everything in the history that is predictively relevant. Knowing $\mathcal{H}_t$ in addition to $M_t$ provides no further predictive power.

When $S = 0$: the model captures nothing predictively relevant.

Perfect sufficiency ($S = 1$) is an ideal. Real models are approximately sufficient, and the degree of sufficiency is itself a measure of model quality.

**Convention when denominator vanishes.** If the environment is memoryless (pure noise), the history carries no predictive information: $I(\mathcal{H}_t; o_{t+1:\infty} \mid a_{t:\infty}) = 0$, making the denominator zero. In this case, define $S(M_t) \equiv 1$: any model — including an empty one — is trivially sufficient because there is nothing predictively relevant to compress.

**Note on action conditioning.** The definition conditions on the full future action sequence $a_{t:\infty}$, which makes $S$ a property of the model's *representational capacity* independent of the agent's policy. In practice, sufficiency is policy-relative: a model may be sufficient under one policy class $\Pi$ but not another. When operationalizing $S$ — for instance, estimating it empirically or using it as an optimization target — it is often more tractable to define $S_\Pi(M_t)$ by restricting the future actions to those reachable under a policy class $\Pi$, or by taking the expectation over an intervention distribution on actions. The full-sequence definition is the theoretical ideal; the policy-conditional form is its practical counterpart.

## The Recursive Property

When the model is a sufficient statistic ($S \approx 1$), a critical property follows: the model can be **updated recursively** without reprocessing the full history:

*[Derived (Conditional on Sufficiency)]*
$$M_t = f(M_{t-1}, o_t, a_{t-1})$$

This is not merely convenient — it is what makes real-time adaptation physically possible. An agent that must reprocess its entire history on each observation would face unbounded computational cost as history grows.

The function $f$ is the **update function** — the mechanism by which new information is incorporated into the model. Its properties are the subject of TF-05 and TF-06.

## Model Quality as Compression Efficiency

The model faces a fundamental trade-off formalized by the **information bottleneck**:

*[Formulation (Optimization Objective)]*
$$\phi^* = \arg\min_{\phi} \left[ I(M_t; \mathcal{H}_t) - \beta \cdot I(M_t; o_{t+1:\infty} \mid a_{t:\infty}) \right]$$

- $I(M_t; \mathcal{H}_t)$ measures **compression cost** — how much of the history the model retains
- $I(M_t; o_{t+1:\infty} \mid a_{t:\infty})$ measures **predictive power** — how much the model can predict
- $\beta$ controls the trade-off: higher $\beta$ favors prediction; lower favors compression

Varying $\beta$ traces a Pareto frontier of optimal models. This IS the rate-distortion curve for the agent's epistemic problem.

A PID controller's model ($\mathbb{R}^3$) is an aggressively compressed point on this curve — it retains almost nothing of the history but preserves enough for effective control of simple dynamics. A Bayesian posterior retains much more. Neither is universally superior; the optimal point depends on $\mathcal{M}$, the environment's complexity, and the agent's computational constraints.

## Model Class Fitness

The choice of $\mathcal{M}$ constrains what models are representable. If $\mathcal{M}$ cannot contain any good sufficient statistic for the actual environment dynamics, no amount of parameter updating within $\mathcal{M}$ will produce an adequate model.

Define **model class fitness**:

*[Definition]*
$$\mathcal{F}(\mathcal{M}) = \sup_{M \in \mathcal{M}} S(M)$$

The best achievable sufficiency given the model class.

When $\mathcal{F}(\mathcal{M})$ is poor, the agent requires **structural adaptation** — changing $\mathcal{M}$ itself. This is the subject of TF-10.

## Why This Is a Formulation

This document is labeled "Formulation" rather than "Axiom" because it makes a specific modeling choice: we analyze adaptive systems as maintaining compressed predictive representations. This is a representational definition, not a psychological or metaphysical claim — "model" includes any internal state that induces non-random action-history dependence, from a thermostat's bimetallic strip to a Bayesian posterior.

The framing is deliberately broad. An agent whose actions are non-random with respect to outcomes is, by definition, using some function of its history — i.e., a model, however implicit. This makes the formulation nearly tautological within the theory's scope, which is by design: TFT does not claim that all systems "have models" in any deep sense, but rather that analyzing them as maintaining compressed representations is productive when the formal apparatus (sufficiency, information bottleneck, model class fitness) can be meaningfully applied.

The model may be explicit (a Kalman state vector, a Bayesian posterior) or implicit (a subsumption architecture's wiring, a PID controller's three-number state, an organization's culture). The formulation claims only that it *exists*, not that it takes any particular form. The theory's content comes not from this existence claim but from the specific mathematical framework ($S(M_t)$, the information bottleneck, $\mathcal{F}(\mathcal{M})$) applied to it.
