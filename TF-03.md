# TF-03: The Model (Axiom)

Any persisting agent maintains a **model** — a compressed representation of its interaction history that supports prediction and action selection.

## Definitions

**Interaction History** ($\mathcal{H}_t$): The complete record of observations and actions available to the agent:

$$\mathcal{H}_t = (o_1, a_1, o_2, a_2, \ldots, a_{t-1}, o_t)$$

This is the agent's *only* raw material. Everything the agent "knows" must be constructed from this.

**Model** ($M_t$): A compression of the interaction history:

$$M_t = \phi(\mathcal{H}_t)$$

where $\phi: \mathcal{H}^* \to \mathcal{M}$ maps histories to elements of a **model space** $\mathcal{M}$.

**Model Space** ($\mathcal{M}$): The set of representable models. This is a structural choice that constrains what the agent can represent:

| Model Space $\mathcal{M}$ | Instance |
|----------------------------|----------|
| $\mathbb{R}^n \times \mathbb{S}^n_{++}$ (vector + covariance) | Kalman filter |
| $\Delta(\Theta)$ (distributions over parameters) | Bayesian agent |
| $\{Q: \mathcal{S} \times \mathcal{A} \to \mathbb{R}\}$ (value functions) | RL agent |
| Neural network weight space | Deep learning agent |
| $\mathbb{R}^3$ (error, integral, derivative) | PID controller |
| (Procedures, beliefs, culture) | Organization |
| Antibody repertoire + memory cells | Immune system |

## The Sufficient Statistic Property

A model is **adequate** to the degree that it is a sufficient statistic for the history with respect to future prediction. Formally, define **model sufficiency**:

$$S(M_t) = 1 - \frac{I(\mathcal{H}_t \,;\, o_{t+1:\infty} \mid M_t, a_{t:\infty})}{I(\mathcal{H}_t \,;\, o_{t+1:\infty} \mid a_{t:\infty})}$$

When $S = 1$: the model captures everything in the history that is predictively relevant. Knowing $\mathcal{H}_t$ in addition to $M_t$ provides no further predictive power.

When $S = 0$: the model captures nothing predictively relevant.

Perfect sufficiency ($S = 1$) is an ideal. Real models are approximately sufficient, and the degree of sufficiency is itself a measure of model quality.

**Note on action conditioning.** The definition conditions on the full future action sequence $a_{t:\infty}$, which makes $S$ a property of the model's *representational capacity* independent of the agent's policy. In practice, sufficiency is policy-relative: a model may be sufficient under one policy class $\Pi$ but not another. When operationalizing $S$ — for instance, estimating it empirically or using it as an optimization target — it is often more tractable to define $S_\Pi(M_t)$ by restricting the future actions to those reachable under a policy class $\Pi$, or by taking the expectation over an intervention distribution on actions. The full-sequence definition is the theoretical ideal; the policy-conditional form is its practical counterpart.

## The Recursive Property

When the model is a sufficient statistic ($S \approx 1$), a critical property follows: the model can be **updated recursively** without reprocessing the full history:

$$M_t = f(M_{t-1}, o_t, a_{t-1})$$

This is not merely convenient — it is what makes real-time adaptation physically possible. An agent that must reprocess its entire history on each observation would face unbounded computational cost as history grows.

The function $f$ is the **update function** — the mechanism by which new information is incorporated into the model. Its properties are the subject of TF-05 and TF-06.

## Model Quality as Compression Efficiency

The model faces a fundamental trade-off formalized by the **information bottleneck**:

$$\phi^* = \arg\min_{\phi} \left[ I(M_t; \mathcal{H}_t) - \beta \cdot I(M_t; o_{t+1:\infty} \mid a_{t:\infty}) \right]$$

- $I(M_t; \mathcal{H}_t)$ measures **compression cost** — how much of the history the model retains
- $I(M_t; o_{t+1:\infty} \mid a_{t:\infty})$ measures **predictive power** — how much the model can predict
- $\beta$ controls the trade-off: higher $\beta$ favors prediction; lower favors compression

Varying $\beta$ traces a Pareto frontier of optimal models. This IS the rate-distortion curve for the agent's epistemic problem.

A PID controller's model ($\mathbb{R}^3$) is an aggressively compressed point on this curve — it retains almost nothing of the history but preserves enough for effective control of simple dynamics. A Bayesian posterior retains much more. Neither is universally superior; the optimal point depends on $\mathcal{M}$, the environment's complexity, and the agent's computational constraints.

## Model Class Fitness

The choice of $\mathcal{M}$ constrains what models are representable. If $\mathcal{M}$ cannot contain any good sufficient statistic for the actual environment dynamics, no amount of parameter updating within $\mathcal{M}$ will produce an adequate model.

Define **model class fitness**:

$$\mathcal{F}(\mathcal{M}) = \sup_{M \in \mathcal{M}} S(M)$$

The best achievable sufficiency given the model class.

When $\mathcal{F}(\mathcal{M})$ is poor, the agent requires **structural adaptation** — changing $\mathcal{M}$ itself. This is the subject of TF-10.

## Why This Is an Axiom

The claim that persisting agents maintain models is not empirically falsifiable in the intended scope — it follows from the information-theoretic constraints of the situation. An agent that acts on an uncertain environment without ANY compression of past experience into predictions would be selecting actions at random. An agent whose actions are non-random with respect to outcomes is, by definition, using some function of its history — i.e., a model, however implicit.

The model may be explicit (a Kalman state vector, a Bayesian posterior) or implicit (a subsumption architecture's wiring, a PID controller's three-number state, an organization's culture). The axiom claims only that it *exists*, not that it takes any particular form.
