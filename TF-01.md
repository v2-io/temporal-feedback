# TF-01: Scope — Adaptive Agents Under Uncertainty (Scope Definition)

This theory applies to any system consisting of an **agent** coupled to an **environment** through **observation** and **action** channels, where the environment is not fully observable and may change over time.

## Definitions

**Environment** ($\Omega$): The totality of state external to the agent. We make no assumptions about $\Omega$'s structure — it may be continuous or discrete, stationary or non-stationary, deterministic or stochastic, benign or adversarial.

**Agent**: An entity that (1) receives observations from the environment, (2) maintains some internal state, and (3) produces actions that affect the environment. The agent cannot access $\Omega$ directly — its observations are necessarily lossy (formalized below). This is a constitutive feature of the scope: the theory applies to systems where the agent-environment boundary entails information loss.

**Observation space** ($\mathcal{O}$): The set of possible observations available to the agent. Each observation is a lossy, possibly noisy function of the environment state:

*[Definition]*
$$o_t = h(\Omega_t, \varepsilon_t)$$

where $h$ is the observation function and $\varepsilon_t$ represents noise or limits of perception.

**Action space** ($\mathcal{A}$): The set of actions available to the agent. Each action affects the environment:

*[Definition]*
$$\Omega_{t+1} \sim T(\cdot \mid \Omega_t, a_t)$$

where $T$ is the (possibly stochastic) transition function.

**Uncertainty**: The agent knows neither $h$ nor $T$ exactly. These are part of what the agent must approximate.

## Formal Scope

*[Scope Definition]*
$$\mathcal{S}_{\text{TFT}} = \{(Agent, \Omega) : |\mathcal{O}| > 0, \; |\mathcal{A}| > 0, \; H(\Omega_t \mid \mathcal{H}_t) > 0 \}$$

where $\mathcal{H}_t = (o_1, a_1, o_2, a_2, \ldots, a_{t-1}, o_t)$ is the full interaction history (formalized in TF-02 / TF-03). The theory applies wherever there is an agent that observes, acts, and faces residual uncertainty about its environment. The final condition — that uncertainty persists even given the complete action-observation history — is constitutive: if the agent could fully determine $\Omega$ from its history alone, the problem would be trivial.

## Why This Scope

This includes: thermostats, PID controllers, robots, organisms, RL agents, organizations, militaries, immune systems, scientific communities.

This excludes:
- **Pure mathematical structures** — no environment, no uncertainty
- **Closed-form systems** — fully observable, fully deterministic ($H(\Omega_t \mid \mathcal{H}_t) = 0$)
- **Passive observers** — $|\mathcal{A}| = 0$ (Bayesian inference without action is a degenerate case; the theory applies but the action-dependent results are trivially void)

## Note on Temporal Indexing

The index $t$ is used for notational convenience. The theory's primary formulation is **event-driven** (see TF-04): observations and actions occur as events in continuous time at potentially different and variable rates. The discrete notation $t = 1, 2, \ldots$ is the special case where events arrive at uniform intervals on a single channel.
