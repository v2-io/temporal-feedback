# Appendix A: Lyapunov Stability Analysis for Adaptive Tempo

**Epistemic status**: The setup and assumptions are *definitions*. Propositions A.1–A.3 and Corollary A.3.1 are *derived* — they follow from the assumptions via standard Lyapunov theory. The assumptions themselves (sector condition, bounded disturbance) are *empirical claims* about the qualitative behavior of real correction dynamics. Proposition A.4 is a *sketch* whose rigorous treatment requires specifying structural adaptation dynamics not yet available in TFT.

## Motivation

TF-11 derives the persistence threshold ($\mathcal{T} > \rho$) and steady-state mismatch ($|\delta|_{ss} = \rho/\mathcal{T}$) from a specific linear ODE hypothesis:

$$\frac{d|\delta|}{dt} = -\mathcal{T} \cdot |\delta| + \rho$$

This is explicitly labeled in TF-11 as a first-order approximation. The linear form yields clean closed-form results but commits to a specific functional relationship between mismatch magnitude and correction rate. As noted in TF-11 Open Question #1, the true correction dynamics are almost certainly nonlinear — exhibiting saturation at large mismatch, threshold effects near zero, and structural breakdown when the model class is exhausted.

A Lyapunov approach proves persistence and stability under much weaker assumptions: any correction dynamics satisfying qualitative monotonicity properties. The results below are strictly more general than TF-11's linear analysis — the linear case is recovered as a special case where the sector bounds coincide.

### What This Analysis Illuminates

1. **Persistence without linearity.** The persistence threshold becomes a theorem about general dynamics, not about one specific ODE.

2. **Stability margin / shock tolerance.** How much sudden environmental change an agent can absorb before divergence — a basin-of-attraction characterization richer than the linear analysis provides.

3. **Adversarial destabilization as formal instability.** "Getting inside the opponent's loop" as a Lyapunov instability result: one agent drives the other's state out of its basin of attraction.

4. **Structural adaptation trigger from dynamics.** When the correction function's sector condition breaks down, the Lyapunov function stops decreasing — a dynamical signal that parametric adaptation has exhausted the model class (connecting to TF-10).

5. **Effects spiral as positive-feedback instability.** Boyd's cascading disorientation derived from coupled Lyapunov dynamics rather than asserted as qualitative observation.

### What This Analysis Does NOT Illuminate

1. **Quantitative steady-state values.** Lyapunov gives *bounds*, not exact values. We get "$\|\delta\|$ is bounded by $R^*$" but not "$|\delta| \to \rho/\mathcal{T}$ exactly." The linear analysis (TF-11) remains necessary for quantitative predictions.

2. **Convergence rates.** Standard Lyapunov tells you stable/unstable, not how fast. Exponential stability results exist but require additional assumptions that effectively recover the linear case.

3. **Optimal gain structure.** Lyapunov is about dynamics, not about what the control law should look like. The uncertainty ratio principle ($\eta^* = U_M/(U_M + U_o)$, TF-06) comes from estimation theory, not stability theory. These are complementary, not competing.

4. **Exploration-exploitation balance.** The CIY-integrated policy objective (TF-07 or TF-08) is a decision-theoretic question, not a stability question. Lyapunov might give a *constraint* on policy (don't let mismatch leave the basin), but not the *optimal* policy.

5. **Model sufficiency.** TF-03's information bottleneck and sufficient statistic framework is information-theoretic. Lyapunov adds nothing to it directly — though the *consequences* of sufficiency (how fast mismatch decays) are exactly what Lyapunov analyzes.

6. **Causal structure.** TF-02's causality grounding is about the temporal ordering of events and Pearl's hierarchy — prior to and independent of dynamical stability.

---

## Setup

Let $\delta(t) \in \mathbb{R}^n$ be the mismatch vector — the difference between the model's predictions and reality across $n$ observable dimensions. The vector treatment connects to the tensor-tempo extension flagged in TF-11 Open Question #4.

The mismatch dynamics are:

$$\frac{d\delta}{dt} = -F(\mathcal{T}, \delta) + w(t)$$

where:

- $F(\mathcal{T}, \delta)$ is the **correction function** — how the agent's adaptive process reduces mismatch. This subsumes the update gain $\eta^*$, event rate $\nu$, and the structure of the update rule (TF-06).
- $w(t)$ is the **disturbance** — new mismatch introduced by environmental change, with $\|w(t)\| \leq \rho$ (bounded disturbance rate).

The linear case from TF-11 has $F(\mathcal{T}, \delta) = \mathcal{T} \cdot \delta$.

## Assumptions on $F$

We require only qualitative properties, not a specific functional form:

**(A1) Zero correction at zero mismatch:**

$$F(\mathcal{T}, 0) = 0$$

No correction is applied when the model perfectly matches reality.

**(A2) Monotone correction (sector condition):**

There exist $\alpha, \beta > 0$ with $0 < \alpha \leq \beta$ such that:

$$\alpha \|\delta\|^2 \leq \delta^T F(\mathcal{T}, \delta) \leq \beta \|\delta\|^2 \quad \forall \delta$$

The correction function always points "inward" (reducing mismatch), and its magnitude is bounded above and below relative to $\|\delta\|^2$. The linear case has $\alpha = \beta = \mathcal{T}$. A saturating correction has $\alpha$ decreasing for large $\|\delta\|$. A threshold correction has $\alpha = 0$ for small $\|\delta\|$.

For the main results, we use the weaker local form:

**(A2') Local sector condition:**

There exists a region $\mathcal{B}_R = \{\delta : \|\delta\| \leq R\}$ and $\alpha > 0$ such that:

$$\delta^T F(\mathcal{T}, \delta) \geq \alpha \|\delta\|^2 \quad \forall \delta \in \mathcal{B}_R$$

This allows the correction to break down outside $\mathcal{B}_R$ — the structural adaptation regime of TF-10.

**(A3) Tempo monotonicity:**

For fixed $\delta$, $\delta^T F(\mathcal{T}, \delta)$ is monotone increasing in $\mathcal{T}$. Higher tempo means faster correction.

**Connection to TFT parameters.** The sector parameter $\alpha$ is determined by the adaptive tempo $\mathcal{T}$ and the structure of the correction function. In the linear case, $\alpha = \mathcal{T} = \sum_k \nu^{(k)} \cdot \eta^{(k)*}$. In nonlinear cases, $\alpha$ represents the *worst-case* correction efficiency within the valid region — the minimum ratio of correction power to mismatch magnitude. The radius $R$ represents the model class capacity: how large a mismatch can grow before the correction mechanism fails (i.e., before the sector condition ceases to hold), at which point structural adaptation (TF-10) becomes necessary.

## Candidate Lyapunov Function

$$V(\delta) = \frac{1}{2}\|\delta\|^2$$

This is the simplest choice: positive definite, radially unbounded, continuously differentiable. Its level sets $V = c$ are spheres of radius $\sqrt{2c}$ in mismatch space.

---

## Proposition A.1: Bounded Mismatch (Single Agent)

**Statement.** Under (A1), (A2'), (A3), with bounded disturbance $\|w(t)\| \leq \rho$, the mismatch $\delta(t)$ is **ultimately bounded**: there exists $R^* > 0$ such that $\|\delta(t)\| \leq R^*$ for all sufficiently large $t$, provided $R^* < R$ (the ultimately bounded region fits within the sector-condition region).

**Proof.**

Compute $\dot{V}$ along trajectories:

$$\dot{V} = \delta^T \dot{\delta} = \delta^T[-F(\mathcal{T}, \delta) + w(t)]$$
$$= -\delta^T F(\mathcal{T}, \delta) + \delta^T w(t)$$

By (A2'): $\delta^T F(\mathcal{T}, \delta) \geq \alpha\|\delta\|^2$

By Cauchy-Schwarz: $\delta^T w(t) \leq \|\delta\| \cdot \|w(t)\| \leq \rho\|\delta\|$

Therefore:

$$\dot{V} \leq -\alpha\|\delta\|^2 + \rho\|\delta\| = -\|\delta\|(\alpha\|\delta\| - \rho)$$

$\dot{V} < 0$ whenever $\|\delta\| > \rho/\alpha$.

Define $R^* = \rho/\alpha$. Outside the ball $\mathcal{B}_{R^*}$, the Lyapunov function is strictly decreasing, so trajectories are driven inward. Any trajectory entering $\mathcal{B}_{R^*}$ remains in a neighborhood of it (with possible oscillation at the boundary due to the disturbance).

The agent persists iff $R^* < R$, i.e., iff $\rho/\alpha < R$, i.e., iff $\alpha > \rho/R$. $\square$

**Interpretation.** The ultimately bounded region has radius $R^* = \rho/\alpha$. In the linear case, $\alpha = \mathcal{T}$, recovering TF-11's steady-state result $R^* = \rho/\mathcal{T}$ exactly. But Proposition A.1 holds for *any* correction function satisfying the sector condition, not just the linear one.

**The persistence threshold, generalized.** The agent persists (mismatch remains bounded within the model class capacity) iff $\rho/\alpha < R$. If the correction function breaks down (A2' fails) before $R^*$ is reached, the agent may diverge. This IS TF-10's structural adaptation trigger: when $\rho/\alpha > R$ (the environment demands more correction than the model class can provide), parametric adaptation fails and structural change is required.

**Note on the bounded-disturbance assumption.** Proposition A.1 requires $\|w(t)\| \leq \rho$ — that disturbance magnitude has a finite upper bound. This is appropriate for the typical operating regime of most adaptive systems, but excludes heavy-tailed (e.g., power-law distributed) environmental shocks where $\|w(t)\|$ can exceed any finite bound with non-negligible probability. Financial crises, ecological catastrophes, and strategic surprise are examples where the bounded-disturbance assumption may be violated. For such environments, stochastic Lyapunov methods — input-to-state stability in probability (ISSp), martingale-based stability, or moment bounds on stochastic Lyapunov functions — would be needed to characterize persistence in a probabilistic rather than deterministic sense. The bounded case gives worst-case guarantees for the typical regime; extreme tail events are better understood as triggers for structural adaptation (TF-10) rather than as disturbances to be absorbed parametrically.

---

## Proposition A.2: Stability Margin (Adaptive Reserve)

**Statement.** Under the conditions of A.1, the agent can tolerate a sudden increase in disturbance rate of:

$$\Delta\rho^* = \alpha R - \rho$$

without mismatch diverging (where $R$ is the radius of the sector-condition region from A2'). Beyond this, $R^*$ exceeds $R$ and the correction function may fail.

**Proof.** After a shock, the new disturbance rate is $\rho + \Delta\rho$. The new ultimately bounded radius is $(\rho + \Delta\rho)/\alpha$. This remains within the valid region iff $(\rho + \Delta\rho)/\alpha \leq R$, i.e., $\Delta\rho \leq \alpha R - \rho$. $\square$

**Interpretation.** $\Delta\rho^*$ is the agent's **adaptive reserve** — how much additional environmental volatility it can absorb before its model breaks down. This is a single number characterizing an agent's robustness to shock:

- An agent operating well below capacity ($\rho \ll \alpha R$) has a large reserve — it is **robust**.
- An agent near its limit ($\rho \approx \alpha R$) has a small reserve — it is **fragile**.

**Domain instances:**

| Domain | Large $\Delta\rho^*$ (robust) | Small $\Delta\rho^*$ (fragile) |
|--------|-------------------------------|-------------------------------|
| Control | Kalman filter on slow target | Same filter on erratic target |
| Biology | Organism in stable niche | Same organism under climate change |
| Organization | Well-capitalized firm, stable market | Startup in volatile market |
| Military | Force with operational depth | Force at culmination point |

---

## Proposition A.3: Adversarial Destabilization

**Statement.** When two agents $A$ and $B$ are coupled such that $A$'s actions contribute to $B$'s disturbance rate, Agent $A$ can drive Agent $B$ outside $B$'s invariant region — causing $B$'s correction mechanism to break down — when $A$'s effective disruption exceeds $B$'s adaptive reserve.

**Setup.** Let both agents satisfy (A1), (A2'), (A3) with respective parameters $(\alpha_A, R_A, \rho_{A,\text{base}})$ and $(\alpha_B, R_B, \rho_{B,\text{base}})$. The coupling:

$$\rho_B = \rho_{B,\text{base}} + \gamma_A \cdot \mathcal{T}_A$$

where $\gamma_A > 0$ represents the effectiveness of $A$'s actions at disrupting $B$'s environment. (This factor depends on coupling strength, observability, and action impact — the factors in TF-01's coupling spectrum.)

**Proof sketch.**

$B$'s ultimately bounded radius under coupled dynamics is:

$$R^*_B = \frac{\rho_{B,\text{base}} + \gamma_A \cdot \mathcal{T}_A}{\alpha_B}$$

$B$ diverges (exits its sector-condition region) when $R^*_B > R_B$, i.e., when:

$$\gamma_A \cdot \mathcal{T}_A > \alpha_B R_B - \rho_{B,\text{base}} = \Delta\rho^*_B$$

That is:

$$\mathcal{T}_A > \frac{\Delta\rho^*_B}{\gamma_A}$$

Symmetrically, $B$ destabilizes $A$ when:

$$\mathcal{T}_B > \frac{\Delta\rho^*_A}{\gamma_B}$$

The adversarial outcome depends on whether either agent can push the other past its stability limit. $\square$

**Interpretation.** "Getting inside the opponent's OODA loop" has a precise Lyapunov characterization: Agent $A$ destabilizes Agent $B$ when $A$'s tempo, multiplied by coupling effectiveness, exceeds $B$'s adaptive reserve $\Delta\rho^*_B$. This is richer than TF-11's linear steady-state ratio ($|\delta_B|/|\delta_A| = \mathcal{T}_A/\mathcal{T}_B$) because it captures:

- **Asymmetric coupling** ($\gamma_A \neq \gamma_B$): an agent with lower tempo but higher coupling effectiveness can still win.
- **Finite reserves**: an agent with very high $\mathcal{T}$ but operating near its model-class limit ($\Delta\rho^*$ small) is vulnerable despite high tempo.
- **Structural collapse**: when $R^*_B > R_B$, the failure mode is not merely "large mismatch" but "correction mechanism breakdown" — connecting to TF-10's structural adaptation requirement.

The linear analysis in TF-11 gives the steady-state ratio — a clean quantitative result. Proposition A.3 gives the qualitative result: under what conditions does $B$ *fail entirely*, not merely fall behind. The linear analysis tells you the score; the Lyapunov analysis tells you when the game is over.

---

## Corollary A.3.1: The Effects Spiral

**Statement.** When Agent $B$ is driven past its stability boundary ($R^*_B > R_B$), and $B$'s degrading model causes $B$'s actions to become erratic in a way that increases $A$'s coupling effectiveness ($\gamma_A$ increases with $\|\delta_B\|$), the result is a positive-feedback Lyapunov instability.

**Mechanism.** Once $B$ exits $\mathcal{B}_{R_B}$:

$$\|\delta_B\| \uparrow \;\Rightarrow\; B\text{'s actions become erratic} \;\Rightarrow\; \gamma_A \uparrow \;\Rightarrow\; \rho_B \uparrow \;\Rightarrow\; \|\delta_B\| \uparrow$$

With $\gamma_A$ now an increasing function of $\|\delta_B\|$, the disturbance term in $B$'s dynamics grows superlinearly. $\dot{V}_B > 0$ and increasing — mismatch accelerates away from the stability region.

**Interpretation.** This is Boyd's **effects spiral** — cascading disorientation of the slower adversary — derived here from Lyapunov instability with positive-feedback coupling rather than asserted as qualitative military doctrine. The spiral terminates only when $B$ undergoes structural adaptation (TF-10 — changing the model class, reorganizing command structure, adopting fundamentally new doctrine) or ceases to function as an adaptive agent entirely.

---

## Proposition A.4: Multi-Timescale Stability (Sketch)

**Status**: This is a *sketch*, not a complete result. Making it rigorous requires specifying the dynamics of deeper adaptive levels more precisely than TFT currently provides. The framework and approach are presented here as a guide for future development.

### The General $N$-Timescale System

The temporal nesting in TF-11 creates a coupled multi-timescale system with $N$ levels. Singular perturbation theory provides tools to analyze such systems. Define a hierarchy of state variables:

$$x^{(1)}, \; x^{(2)}, \; \ldots, \; x^{(N)}$$

where $x^{(1)}$ is the fastest (e.g., mismatch at the reactive/parametric level) and $x^{(N)}$ is the slowest (e.g., architectural or meta-structural state). The coupled dynamics:

$$\dot{x}^{(k)} = \frac{1}{\epsilon_k} \, G^{(k)}\!\left(x^{(1)}, \ldots, x^{(N)}\right) + w^{(k)}(t)$$

where $\epsilon_1 \ll \epsilon_2 \ll \cdots \ll \epsilon_N$ encode the timescale separation and each $G^{(k)}$ may depend on the states at all levels (since each level operates on the output of the levels below and is parameterized by the levels above).

### The Two-Timescale Special Case

The simplest nontrivial instance has $N = 2$:

- Fast state $x^{(1)} = \delta$ (mismatch under parametric adaptation)
- Slow state $x^{(2)} = \mathcal{M}$ (model class, changing on a structural timescale)

$$\dot{x}^{(1)} = -F(\mathcal{T}, x^{(1)}; x^{(2)}) + w(t) \quad \text{(fast: parametric adaptation)}$$
$$\dot{x}^{(2)} = \epsilon \, G(x^{(1)}, x^{(2)}) \quad \text{(slow: structural adaptation)}$$

where $\epsilon \ll 1$ reflects the timescale separation (structural dynamics evolve on a much slower timescale) and $F$ depends on $x^{(2)}$ (the correction function is determined by the current model class).

### Sketch of Approach (General Case)

The standard singular perturbation result (Tikhonov's theorem, generalized) applies layer by layer: if level $k$ is stable for each fixed configuration of the slower levels $k+1, \ldots, N$ (each level has a stable attractor given the levels above it), and each successive slow manifold is itself stable, then the composite $N$-level system is stable.

TF-11's convergence constraint $\nu_{n+1} \ll \nu_n$ is the condition ensuring sufficient timescale separation at each boundary — i.e., $\epsilon_k / \epsilon_{k+1} \ll 1$ for each $k$. When this separation is violated between any adjacent pair, the faster level's transients contaminate the slower level's dynamics, potentially destabilizing the composite system.

### What's Missing for a Full Result

The dynamics $G^{(k)}$ for levels deeper than parametric adaptation are not yet specified in TFT. TF-10 gives the *trigger condition* for structural change (persistent residual patterns indicating model class inadequacy) but not the *dynamics* of how change at deeper levels proceeds. Specifying these would require theories of how agents search over model classes, modify their own architecture, or restructure their adaptive mechanisms — open problems in RL (architecture search, meta-learning), biology (evolutionary dynamics, developmental plasticity), and organizational theory (institutional change).

The sketch suggests that TF-11's convergence constraint is not merely a heuristic but a formal condition for composite stability across arbitrarily many timescales; making this precise awaits better specification of the deeper-level dynamics.

**Note on applicability to LLM systems.** LLMs will likely involve many parallel adaptive processes — pretraining (slowest), fine-tuning, LoRA-style online adaptation, in-context learning, retrieval/RAG updates, tool-use feedback, and within-generation attention dynamics — without clean boundaries between "parametric" and "structural." The $N$-timescale framework accommodates this naturally: each mechanism operates at its characteristic rate, and the stability analysis requires only that adjacent timescales be sufficiently separated, regardless of how many levels exist or how they are labeled.

---

## Summary of Results

| Result | What it proves | Assumptions | Linear case recovery |
|--------|---------------|-------------|---------------------|
| **A.1** (Bounded Mismatch) | Mismatch ultimately bounded by $R^* = \rho/\alpha$ | (A1), (A2'), bounded $\rho$ | $\alpha = \mathcal{T}$ gives $R^* = \rho/\mathcal{T}$ (Prop 11.1) |
| **A.2** (Stability Margin) | Adaptive reserve $\Delta\rho^* = \alpha R - \rho$ | Same as A.1 | $R \to \infty$ for linear (always stable if $\mathcal{T} > 0$) |
| **A.3** (Adversarial) | $A$ destabilizes $B$ when $\gamma_A \mathcal{T}_A > \Delta\rho^*_B$ | Both agents satisfy A.1; linear coupling | Recovers tempo-ratio advantage |
| **A.3.1** (Effects Spiral) | Positive-feedback instability post-destabilization | $\gamma_A$ increasing in $\|\delta_B\|$ | Not present in linear analysis |
| **A.4** (Multi-Timescale) | *Sketch*: $N$-level timescale separation → composite stability | $\epsilon_k / \epsilon_{k+1} \ll 1$; each level stable given slower levels | Recovers convergence constraint $\nu_{n+1} \ll \nu_n$ |

**Key value of the Lyapunov approach.** The persistence threshold and adversarial results are no longer contingent on the linear hypothesis. They hold for any correction dynamics satisfying the sector condition — a mild qualitative assumption that says "correction points inward and is proportional (within bounds) to mismatch." This is a significant epistemic upgrade: from *hypothesis-dependent* to *robust under qualitative assumptions*.
